{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOo8WxuAEmXmpUWO+13z8PY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaxPr1me/Ontario_Scope2_EmissionFactor/blob/main/Emission_Factors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear any previous variables or outputs (not needed in Python, but done here for clarity)\n",
        "# This is just a visual reset equivalent to `clc; clear all; close all;` in MATLAB\n",
        "%reset -f"
      ],
      "metadata": {
        "id": "j46lm_ThMaRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmUTXzHaC_Jj"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access the IESO data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hC1oHCVMOHu",
        "outputId": "d45d3496-f0be-4ba2-8fa4-46d58021e374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the base path relative to where the notebook is stored\n",
        "# The notebook is in 'My Drive/Code - Emission Factors', so we append the relative path to the data\n",
        "base_path = '/content/drive/My Drive/Code - Emission Factors/IESO Data/'\n",
        "\n",
        "# Define file path templates for the different data types\n",
        "supply_template = 'Supply/GOC-{}.xlsx'\n",
        "demand_template = 'Demand/PUB_DemandZonal_{}.csv'\n",
        "generator_list_template = 'Generator_List.xlsx'\n",
        "transmission_template = 'Transmission/PUB_IntertieScheduleFlowYear_{}.csv'\n",
        "\n",
        "# Initialize an empty dictionary to store data for each year\n",
        "data = {}"
      ],
      "metadata": {
        "id": "2B0mbXaaMeMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each year from 2016 to 2023\n",
        "for year in range(2016, 2024):\n",
        "    # Generate file paths based on the year using the relative base path\n",
        "    supply_file = os.path.join(base_path, supply_template.format(year))\n",
        "    demand_file = os.path.join(base_path, demand_template.format(year))\n",
        "    generator_list_file = os.path.join(base_path, generator_list_template)\n",
        "    transmission_file = os.path.join(base_path, transmission_template.format(year))\n",
        "\n",
        "    # Load files and handle missing data gracefully\n",
        "    try:\n",
        "        # Check if the files exist before trying to load them\n",
        "        if os.path.exists(supply_file) and os.path.exists(demand_file) and os.path.exists(generator_list_file) and os.path.exists(transmission_file):\n",
        "            # Load supply data (from Excel)\n",
        "            supply_data = pd.read_excel(supply_file)\n",
        "            # Load demand data (from CSV)\n",
        "            demand_data = pd.read_csv(demand_file)\n",
        "            # Load generator list\n",
        "            generator_list = pd.read_excel(generator_list_file)\n",
        "            # Load transmission data\n",
        "            transmission_data = pd.read_csv(transmission_file)\n",
        "\n",
        "            # Store the data in a dictionary\n",
        "            data[year] = {\n",
        "                'supply': supply_data,\n",
        "                'demand': demand_data,\n",
        "                'generator_list': generator_list,\n",
        "                'transmission': transmission_data\n",
        "            }\n",
        "        else:\n",
        "            print(f\"Files for {year} are missing. Skipping this year.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data for {year}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAU0obhbSW2x",
        "outputId": "7ce29950-64f1-4791-dd29-b3d01c38e0d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files for 2016 are missing. Skipping this year.\n",
            "Files for 2017 are missing. Skipping this year.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Once loaded, let's clean and process the data\n",
        "\n",
        "# Function to replace NaN values with 0 in all numerical columns\n",
        "def clean_data(df):\n",
        "    return df.fillna(0)\n",
        "\n",
        "for year in data:\n",
        "    # Clean supply, demand, and transmission data\n",
        "    data[year]['supply'] = clean_data(data[year]['supply'])\n",
        "    data[year]['demand'] = clean_data(data[year]['demand'])\n",
        "    data[year]['transmission'] = clean_data(data[year]['transmission'])"
      ],
      "metadata": {
        "id": "XZb9i51oUThL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's extract the timestamps from the 'txt' variable equivalent in the supply data.\n",
        "# Assuming that the first column of the supply data contains the date-time information\n",
        "\n",
        "for year in data:\n",
        "    try:\n",
        "        # Convert the 'Date' column to a datetime object\n",
        "        time_data = pd.to_datetime(data[year]['supply'].iloc[:, 0], errors='coerce')  # Coerce errors to handle bad dates\n",
        "\n",
        "        # Add the hours from the 'Hour' column as a time delta\n",
        "        hours_data = pd.to_numeric(data[year]['supply'].iloc[:, 1], errors='coerce')\n",
        "        if hours_data.notnull().all():\n",
        "            time_data = time_data + pd.to_timedelta(hours_data - 1, unit='h')  # Subtract 1 to account for 1-based hour index\n",
        "\n",
        "        # Store the processed time data\n",
        "        data[year]['time'] = time_data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing time data for {year}: {e}\")"
      ],
      "metadata": {
        "id": "6P9-ejYeUjrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define regions and technologies\n",
        "regions = ['Northwest', 'Northeast', 'Ottawa', 'East', 'Toronto', 'Essa', 'Bruce', 'Southwest', 'Niagara', 'West']\n",
        "technologies = ['Biofuel', 'Hydro', 'Natural Gas', 'Nuclear', 'Solar', 'Wind']\n",
        "\n",
        "# Extract demand data for each zone (from demand CSV file)\n",
        "demand_data = data[year]['demand']\n",
        "\n",
        "# Create a dictionary to hold the demand data for each region\n",
        "demand_by_region = {}\n",
        "for i in range(1, 11):  # 10 regions\n",
        "    demand_by_region[i] = demand_data.iloc[:, 2 + i].to_numpy()  # Columns 3 to 12 for each region's demand"
      ],
      "metadata": {
        "id": "opqQEwLca-1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize generator data structure for each region and technology\n",
        "# Gen will be a dictionary of dictionaries, where Gen[region][technology] stores the data\n",
        "gen = {region: {tech: np.zeros(len(data[year]['time'])) for tech in technologies} for region in regions}\n",
        "\n",
        "# Generator count\n",
        "gencount = 0\n",
        "\n",
        "# Loop through generator data and map it to the correct region and technology\n",
        "for col_idx in range(3, len(data[year]['supply'].columns)):  # Starting at column 4 (index 3)\n",
        "    generator_name = data[year]['supply'].columns[col_idx]\n",
        "\n",
        "    # Loop through the generator list (assuming it's stored in data[year]['generator_list'])\n",
        "    for gen_idx, row in data[year]['generator_list'].iterrows():\n",
        "        if generator_name == row[0]:  # Compare generator names (column 0)\n",
        "            # Determine the region\n",
        "            region_name = row[2]  # Assuming region is in column 3\n",
        "            if region_name in regions:\n",
        "                region = region_name\n",
        "\n",
        "            # Determine the technology\n",
        "            tech_name = row[1]  # Assuming technology is in column 2\n",
        "            if tech_name in technologies:\n",
        "                technology = tech_name\n",
        "\n",
        "            # Add the generator data to the correct region and technology\n",
        "            gen[region][technology] = np.column_stack((gen[region][technology], data[year]['supply'].iloc[:, col_idx]))\n",
        "\n",
        "            # Replace NaN values with 0\n",
        "            gen[region][technology][np.isnan(gen[region][technology])] = 0\n",
        "\n",
        "            # Increment the generator count\n",
        "            gencount += 1\n",
        "            break  # Move to the next generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhmwjultbJ6f",
        "outputId": "d9b6735d-a1b9-45e9-eb39-595515594be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-8c019e74cd4f>:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  if generator_name == row[0]:  # Compare generator names (column 0)\n",
            "<ipython-input-13-8c019e74cd4f>:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  region_name = row[2]  # Assuming region is in column 3\n",
            "<ipython-input-13-8c019e74cd4f>:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  tech_name = row[1]  # Assuming technology is in column 2\n"
          ]
        }
      ]
    }
  ]
}