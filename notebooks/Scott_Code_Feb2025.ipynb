{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM5XrqDu5zG4zx8rQzGVrjy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LHIFC5qXR4w2"},"outputs":[],"source":["## 1. Import Necessary Libraries\n","import pandas as pd\n","import numpy as np\n","import os\n","import requests\n","import time"]},{"cell_type":"code","source":["## 2. Install Dependencies (if running in Colab)\n","def install_dependencies():\n","    try:\n","        import google.colab\n","        !pip install pandas numpy\n","    except ImportError:\n","        pass  # Not running in Colab"],"metadata":{"id":"vkQQTzN9SEJR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 3. Helper Functions\n","### 3.1 Fetch data from URLs\n","def download_file(url, save_path):\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        with open(save_path, 'wb') as f:\n","            f.write(response.content)\n","        print(f\"Downloaded: {save_path}\")\n","    else:\n","        raise Exception(f\"Failed to download {url} (status code {response.status_code})\")\n","\n","### 3.2 Parse and Clean Generator Data\n","def parse_and_clean_generator_month(file_path):\n","    # Read the file line-by-line to preprocess and fix inconsistencies\n","    cleaned_rows = []\n","    with open(file_path, 'r') as file:\n","        lines = file.readlines()\n","        for line in lines[3:]:  # Skip the first three rows (headers)\n","            line = line.strip().rstrip(',')  # Remove trailing spaces and commas\n","            fields = line.split(',')  # Split the line into fields\n","            if len(fields) == 28:  # Only keep rows with the correct number of fields\n","                cleaned_rows.append(fields)\n","            else:\n","                print(f\"Skipped row with {len(fields)} fields: {line}\")\n","\n","    # Convert the cleaned rows into a DataFrame\n","    raw_df = pd.DataFrame(cleaned_rows, columns=[\n","        'Delivery Date', 'Generator', 'Fuel Type', 'Measurement',\n","        'Hour 1', 'Hour 2', 'Hour 3', 'Hour 4', 'Hour 5', 'Hour 6',\n","        'Hour 7', 'Hour 8', 'Hour 9', 'Hour 10', 'Hour 11', 'Hour 12',\n","        'Hour 13', 'Hour 14', 'Hour 15', 'Hour 16', 'Hour 17', 'Hour 18',\n","        'Hour 19', 'Hour 20', 'Hour 21', 'Hour 22', 'Hour 23', 'Hour 24'\n","    ])\n","\n","    return raw_df\n","\n","### 3.3 Aggregate Generator Data for a Year\n","def aggregate_generator_data(year):\n","    base_url = \"https://reports-public.ieso.ca/public/GenOutputCapabilityMonth/\"\n","    data_dir = \"data\"\n","    os.makedirs(data_dir, exist_ok=True)\n","\n","    # Prepare list for monthly data\n","    monthly_data = []\n","\n","    for month in range(1, 13):\n","        month_str = f\"{month:02d}\"\n","        file_name = f\"PUB_GenOutputCapabilityMonth_{year}{month_str}.csv\"\n","        file_url = f\"{base_url}{file_name}\"\n","        local_path = os.path.join(data_dir, file_name)\n","\n","        # Download the file\n","        download_file(file_url, local_path)\n","\n","        # Parse and clean the monthly data\n","        month_data = parse_and_clean_generator_month(local_path)\n","\n","        # Remove any rows matching the header row\n","        header_row = [\n","            'Delivery Date', 'Generator', 'Fuel Type', 'Measurement',\n","            'Hour 1', 'Hour 2', 'Hour 3', 'Hour 4', 'Hour 5', 'Hour 6',\n","            'Hour 7', 'Hour 8', 'Hour 9', 'Hour 10', 'Hour 11', 'Hour 12',\n","            'Hour 13', 'Hour 14', 'Hour 15', 'Hour 16', 'Hour 17', 'Hour 18',\n","            'Hour 19', 'Hour 20', 'Hour 21', 'Hour 22', 'Hour 23', 'Hour 24'\n","        ]\n","        month_data = month_data[~(month_data == header_row).all(axis=1)]\n","\n","        # Remove the header row from subsequent monthly files\n","        if monthly_data:\n","            month_data = month_data[1:]\n","\n","        monthly_data.append(month_data)\n","\n","    # Concatenate all monthly data into a single yearly DataFrame\n","    yearly_data = pd.concat(monthly_data, ignore_index=True)\n","\n","    return yearly_data\n","\n","### 3.4 Transform Generator Data to Match Demand/Trade Flow Format\n","def transform_generator_data(gen_output_df):\n","    # Step 1: Keep only rows where Measurement is \"Output\"\n","    gen_output_df = gen_output_df[gen_output_df['Measurement'] == 'Output']\n","\n","    # Check if there are any rows left after filtering\n","    if gen_output_df.empty:\n","        raise ValueError(\"No rows with 'Output' in the 'Measurement' column.\")\n","\n","    # Step 2: Drop the Measurement column\n","    gen_output_df = gen_output_df.drop(columns=['Measurement'])\n","\n","    # Step 3: Combine Generator and Fuel Type into a single column\n","    gen_output_df['Fuel-Generator'] = gen_output_df['Fuel Type'] + ' - ' + gen_output_df['Generator']\n","    gen_output_df = gen_output_df.drop(columns=['Generator', 'Fuel Type'])\n","\n","    ## Debug: Confirm creation of 'Fuel-Generator'\n","    #print(\"\\nAfter Creating 'Fuel-Generator':\")\n","    #print(gen_output_df[['Fuel-Generator']].head())\n","\n","    # Step 4: Reshape the data to have Hours as rows and Fuel-Generators as columns\n","    melted = gen_output_df.melt(\n","        id_vars=['Delivery Date', 'Fuel-Generator'],  # Include 'Fuel-Generator' here\n","        var_name='Hour',\n","        value_name='Value'\n","    )\n","\n","    ## Debug: Verify the melted DataFrame\n","    #print(\"\\nAfter Melting Data:\")\n","    #print(melted.head())\n","\n","    # Extract numeric hour values, handling NaN values\n","    melted['Hour'] = melted['Hour'].str.extract(r'(\\d+)')\n","    melted = melted.dropna(subset=['Hour'])  # Drop rows where Hour extraction failed\n","    melted['Hour'] = melted['Hour'].astype(int)\n","\n","    # Pivot the data to have one column per Fuel-Generator\n","    reshaped_data = melted.pivot(\n","        index=['Delivery Date', 'Hour'],\n","        columns='Fuel-Generator',\n","        values='Value'\n","    ).reset_index()\n","\n","    # Ensure columns are well-aligned\n","    reshaped_data.columns.name = None  # Remove the multi-index column name\n","\n","    ## Debug: Final reshaped DataFrame\n","    #print(\"\\nFinal Reshaped Data:\")\n","    #print(reshaped_data.head())\n","\n","    return reshaped_data\n","\n","\n","### 3.5 Prompt for Emission Rates\n","def get_emission_rates():\n","    print(\"\\nDo you want to use custom emission rates for generator technologies? (y/n)\")\n","    use_custom = input().strip().lower()\n","\n","    # Default emission rates in t CO2e/GWh\n","    default_rates = {\n","        \"Biofuel\": 6.15,\n","        \"Hydro\": 0,\n","        \"Natural Gas\": 525,\n","        \"Nuclear\": 0.15,\n","        \"Solar\": 6.15,\n","        \"Wind\": 0.74\n","    }\n","\n","    if use_custom == 'y':\n","        print(\"\\nEnter custom emission rates (t CO2e/GWh). Press Enter to keep default values:\")\n","        for tech in default_rates:\n","            user_input = input(f\"{tech} (default {default_rates[tech]}): \").strip()\n","            if user_input:\n","                try:\n","                    default_rates[tech] = float(user_input)\n","                except ValueError:\n","                    print(f\"Invalid input for {tech}, using default value {default_rates[tech]}.\")\n","    else:\n","        print(\"\\nUsing default emission rates.\")\n","\n","    # Display the final emission rates\n","    print(\"\\nFinal Emission Rates (t CO2e/GWh):\")\n","    print(pd.DataFrame.from_dict(default_rates, orient='index', columns=['Emission Rate (t CO2e/GWh)']))\n","\n","    # Convert to t CO2e/MWh for calculations\n","    return {tech: rate / 1000 for tech, rate in default_rates.items()}\n","\n","### 3.6 Prompt for Emission Factors of Neighboring Regions\n","def get_neighboring_emission_factors():\n","    print(\"\\nDo you want to use custom emission factors for neighboring regions? (y/n)\")\n","    use_custom = input().strip().lower()\n","\n","    # Default emission factors in t CO2e/GWh\n","    default_factors = {\n","        \"Manitoba\": 2.2,\n","        \"Michigan\": 502,\n","        \"Minnesota\": 463,\n","        \"New York\": 211,\n","        \"Quebec\": 1.7\n","    }\n","\n","    if use_custom == 'y':\n","        print(\"\\nEnter custom emission factors (t CO2e/GWh). Press Enter to keep default values:\")\n","        for region in default_factors:\n","            user_input = input(f\"{region} (default {default_factors[region]}): \").strip()\n","            if user_input:\n","                try:\n","                    default_factors[region] = float(user_input)\n","                except ValueError:\n","                    print(f\"Invalid input for {region}, using default value {default_factors[region]}.\")\n","    else:\n","        print(\"\\nUsing default emission factors.\")\n","\n","    # Display the final emission factors\n","    print(\"\\nFinal Emission Factors for Neighboring Regions (t CO2e/GWh):\")\n","    print(pd.DataFrame.from_dict(default_factors, orient='index', columns=['Emission Factor (t CO2e/GWh)']))\n","\n","    # Convert to t CO2e/MWh for calculations\n","    return {region: factor / 1000 for region, factor in default_factors.items()}\n","\n","### 3.7 Parse and Clean Demand Data\n","def parse_and_clean_demand(file_path):\n","    # Read the file once to find rows to skip\n","    with open(file_path, 'r') as file:\n","        lines = file.readlines()\n","\n","    # Identify rows to skip based on the presence of double backslashes\n","    skip_rows = [i for i, line in enumerate(lines) if '\\\\' in line]\n","\n","    # Read CSV, skipping identified rows\n","    raw_df = pd.read_csv(file_path, skiprows=skip_rows)\n","\n","    # Reset column headers if necessary\n","    raw_df.columns = [str(col).strip() for col in raw_df.columns]\n","\n","    return raw_df\n","\n","### 3.8 Parse and Clean Trade Flow Data\n","def parse_and_clean_trade_flow(file_path):\n","    # Read the file once to find rows to skip\n","    with open(file_path, 'r') as file:\n","        lines = file.readlines()\n","\n","    # Identify rows to skip based on the presence of backslashes\n","    skip_rows = [i for i, line in enumerate(lines) if '\\\\' in line]\n","\n","    # Read CSV, skipping identified rows\n","    raw_df = pd.read_csv(file_path, skiprows=skip_rows, header=None)\n","\n","    # Combine first two rows to form column names\n","    raw_headers = raw_df.iloc[:2].fillna('')\n","    headers = [f\"{str(raw_headers.iloc[0, i]).strip()} {str(raw_headers.iloc[1, i]).strip()}\" for i in range(len(raw_df.columns))]\n","    headers[0] = \"Date\"  # Rename the first column to Date\n","    headers[1] = \"Hour\"  # Rename the second column to Hour\n","\n","    # Ensure the number of headers matches the number of columns\n","    if len(headers) != len(raw_df.columns):\n","        raise ValueError(\"Header length mismatch with columns in the data.\")\n","\n","    raw_df.columns = headers\n","    raw_df = raw_df[2:]  # Drop the first two rows used for headers\n","\n","    return raw_df\n","\n","### 3.9 Transform Trade Flow Data\n","def transform_trade_flow(trade_flow_df):\n","    \"\"\"\n","    Transforms the trade flow DataFrame by keeping relevant columns:\n","    - Retains \"Date\" and \"Hour\" columns.\n","    - Removes columns starting with \"Total\".\n","    - Removes columns ending with \"Imp\" or \"Exp\".\n","    - Keeps only columns ending with \"Flow\".\n","    - Sums columns starting with \"MANITOBA\" into \"MANITOBA Total Flow\".\n","    - Sums columns starting with \"PQ\" into \"QUEBEC Total Flow\".\n","\n","    Args:\n","        trade_flow_df (pd.DataFrame): The original trade flow DataFrame.\n","\n","    Returns:\n","        pd.DataFrame: The transformed trade flow DataFrame.\n","    \"\"\"\n","    # Step 1: Keep only \"Date\" and \"Hour\" columns\n","    transformed_df = trade_flow_df[[\"Date\", \"Hour\"]].copy()\n","\n","    # Step 2: Filter columns ending with \"Flow\", excluding those starting with \"Total\"\n","    flow_columns = [\n","        col for col in trade_flow_df.columns\n","        if col.endswith(\"Flow\") and not col.startswith(\"Total\")\n","    ]\n","\n","    # Append the filtered flow columns to the result\n","    filtered_df = trade_flow_df[flow_columns].copy()\n","\n","    # Step 3: Sum values of columns starting with \"MANITOBA\" into \"MANITOBA Total Flow\"\n","    manitoba_columns = [col for col in filtered_df.columns if col.startswith(\"MANITOBA\")]\n","    transformed_df.loc[:, \"MANITOBA Total Flow\"] = filtered_df[manitoba_columns].astype(float).sum(axis=1)\n","\n","    # Remove the added up MANITOBA columns\n","    filtered_df = filtered_df.drop(columns=manitoba_columns, errors=\"ignore\")\n","\n","    # Step 4: Sum values of columns starting with \"PQ\" into \"QUEBEC Total Flow\"\n","    quebec_columns = [col for col in filtered_df.columns if col.startswith(\"PQ\")]\n","    transformed_df.loc[:, \"QUEBEC Total Flow\"] = filtered_df[quebec_columns].astype(float).sum(axis=1)\n","\n","    # Remove the added up PQ columns\n","    filtered_df = filtered_df.drop(columns=quebec_columns, errors=\"ignore\")\n","\n","    # Append the remaining flow columns\n","    transformed_df = pd.concat([transformed_df, filtered_df], axis=1)\n","\n","    return transformed_df\n","\n","### 3.10 Calculate supply-based emission factors for each timestep\n","def calculate_supply_based_ef(transformed_gen_data, emission_rates):\n","\n","    # Initialize a list for the output data\n","    ef_rows = []\n","    total_output_list = []\n","\n","\n","    # Group columns by technology prefix\n","    tech_prefix_map = {\n","        \"B\": \"Biofuel\",\n","        \"H\": \"Hydro\",\n","        \"G\": \"Natural Gas\",\n","        \"N\": \"Nuclear\",\n","        \"S\": \"Solar\",\n","        \"W\": \"Wind\"\n","    }\n","\n","    # Ensure all cells are properly cleaned and non-numeric entries are handled\n","    transformed_gen_data = transformed_gen_data.apply(lambda col: pd.to_numeric(col, errors='coerce').fillna(0) if col.name not in [\"Delivery Date\", \"Hour\"] else col)\n","\n","    # Loop through each row to calculate EF\n","    for _, row in transformed_gen_data.iterrows():\n","        # Extract date and hour\n","        delivery_date = row[\"Delivery Date\"]\n","        hour = row[\"Hour\"]\n","\n","        # Sum outputs by technology\n","        tech_sums = {tech: 0 for tech in tech_prefix_map.values()}\n","        for col in transformed_gen_data.columns[2:]:\n","            prefix = col[0]\n","            if prefix in tech_prefix_map:\n","                tech = tech_prefix_map[prefix]\n","                value = row[col]\n","                tech_sums[tech] += value\n","\n","        # Calculate total emissions and total output\n","        total_emissions = sum(tech_sums[tech] * emission_rates[tech] for tech in tech_sums)\n","        total_output = sum(tech_sums.values())\n","\n","         # Store total output for this timestep\n","        total_output_list.append({\n","            \"Delivery Date\": delivery_date,\n","            \"Hour\": hour,\n","            \"Total Output\": total_output\n","        })\n","\n","        # Calculate EF in t CO2e/MWh\n","        ef_t_co2e_mwh = total_emissions / total_output if total_output > 0 else 0\n","\n","        # Convert EF to g CO2e/kWh for publishing\n","        ef_g_co2e_kwh = ef_t_co2e_mwh * 1000\n","\n","        # Append results to the list\n","        ef_rows.append({\n","            \"Delivery Date\": delivery_date,\n","            \"Hour\": hour,\n","            \"Supply-based EF (g CO2e/kWh)\": ef_g_co2e_kwh\n","        })\n","\n","    # Convert the results to a DataFrame\n","    supplybased_ef = pd.DataFrame(ef_rows)\n","    total_output_df = pd.DataFrame(total_output_list)\n","\n","\n","    return supplybased_ef, total_output_df\n","\n","### 3.11 Calculate consumption-based emission factors for each timestep.\n","\n","def calculate_consumption_based_ef(supplybased_ef, demand_df, transformed_trade_flow, neighboring_emission_factors, total_output_df):\n","    \"\"\"\n","    Calculate the consumption-based emission factors for each timestep.\n","\n","    Args:\n","        supplybased_ef (pd.DataFrame): Supply-based emission factors.\n","        demand_df (pd.DataFrame): Demand data.\n","        transformed_trade_flow (pd.DataFrame): Preprocessed trade flow data.\n","        neighboring_emission_factors (dict): Emission factors for neighboring regions.\n","        total_output_df (pd.DataFrame): Total output data.\n","\n","    Returns:\n","        pd.DataFrame: Consumption-based emission factors.\n","        pd.DataFrame: Spot-check data for debugging.\n","    \"\"\"\n","    # Check if all inputs have the same length\n","    if not (len(supplybased_ef) == len(demand_df) == len(transformed_trade_flow)):\n","        raise ValueError(\"Input DataFrames (supplybased_ef, demand_df, transformed_trade_flow) must have the same length.\")\n","\n","    # Normalize neighboring_emission_factors keys\n","    neighboring_emission_factors = {key.upper()[:3]: value for key, value in neighboring_emission_factors.items()}\n","\n","    # Initialize lists for results and debugging\n","    consumption_rows = []\n","    spot_check_data = []\n","\n","    total_steps = len(supplybased_ef)\n","    progress_interval = max(1, total_steps // 10)\n","    start_time = time.time()\n","\n","    # Iterate over each timestep\n","    for idx in range(total_steps):\n","        # Extract rows for the current timestep\n","        supply_ef_row = supplybased_ef.iloc[idx]\n","        demand_row = demand_df.iloc[idx]\n","        trade_flow_row = transformed_trade_flow.iloc[idx]\n","        total_output_row = total_output_df.iloc[idx]\n","\n","        # Supply-based EF in g CO2e/kWh to t CO2e/MWh\n","        supply_based_ef_t_co2e_mwh = supply_ef_row[\"Supply-based EF (g CO2e/kWh)\"] / 1000\n","\n","        # Ontario demand and total output\n","        ontario_demand_mwh = demand_row[\"Ontario Demand\"]\n","        total_output_mwh = total_output_row[\"Total Output\"]\n","\n","        # Initialize variables for exports and imports\n","        total_exports_mwh = 0\n","        total_imports_mwh = 0\n","        total_imports_emissions_t_co2e = 0\n","\n","        # Process trade flow data dynamically\n","        for col in transformed_trade_flow.columns:\n","            if col in [\"Date\", \"Hour\"]:\n","                continue\n","\n","            # Extract the region name using the first 3 characters\n","            region = col.split(\" \")[0].upper()[:3]\n","\n","            # Get the flow value, handling NaN gracefully\n","            flow_mwh = trade_flow_row.get(col, 0)\n","            flow_mwh = float(flow_mwh) if pd.notna(flow_mwh) else 0\n","\n","            # Lookup emission factor\n","            applied_factor = neighboring_emission_factors.get(region, 0)\n","            if applied_factor == 0:\n","                print(f\"Warning: No emission factor found for region '{region}'. Defaulting to 0.\")\n","\n","            # Determine whether the flow is import or export\n","            if flow_mwh > 0:  # Net export\n","                total_exports_mwh += flow_mwh\n","            elif flow_mwh < 0:  # Net import\n","                import_mwh = abs(flow_mwh)\n","                total_imports_mwh += import_mwh\n","                total_imports_emissions_t_co2e += import_mwh * applied_factor\n","\n","        # Spot-check data for the timestep\n","        spot_check_data.append({\n","            \"Delivery Date\": supply_ef_row[\"Delivery Date\"],\n","            \"Hour\": supply_ef_row[\"Hour\"],\n","            \"Total Exports (MWh)\": total_exports_mwh,\n","            \"Total Imports (MWh)\": total_imports_mwh,\n","            \"Total Import Emissions (t CO2e)\": total_imports_emissions_t_co2e\n","        })\n","\n","        # Calculate balance difference\n","        net_balance = total_output_mwh - total_exports_mwh + total_imports_mwh\n","        balance_difference_mwh = net_balance - ontario_demand_mwh\n","\n","        # Remove emissions associated with the balance difference\n","        adjusted_emissions_t_co2e = balance_difference_mwh * supply_based_ef_t_co2e_mwh if balance_difference_mwh > 0 else 0\n","\n","        # Calculate consumption-based EF\n","        consumption_ef_t_co2e_mwh = (\n","            (supply_based_ef_t_co2e_mwh * total_output_mwh) -\n","            (supply_based_ef_t_co2e_mwh * total_exports_mwh) +\n","            total_imports_emissions_t_co2e -\n","            adjusted_emissions_t_co2e\n","        ) / ontario_demand_mwh if ontario_demand_mwh > 0 else 0\n","\n","        # Convert EF to g CO2e/kWh for publishing\n","        consumption_ef_g_co2e_kwh = consumption_ef_t_co2e_mwh * 1000\n","\n","        # Append the result\n","        consumption_rows.append({\n","            \"Delivery Date\": supply_ef_row[\"Delivery Date\"],\n","            \"Hour\": supply_ef_row[\"Hour\"],\n","            \"Consumption-based EF (g CO2e/kWh)\": consumption_ef_g_co2e_kwh\n","        })\n","\n","        # Progress update every 10% completed\n","        if (idx + 1) % progress_interval == 0 or (idx + 1) == total_steps:\n","            elapsed_time = time.time() - start_time\n","            print(f\"Progress: {idx + 1}/{total_steps} ({(idx + 1) / total_steps * 100:.1f}%) steps completed. Elapsed time: {elapsed_time:.2f} seconds.\")\n","\n","    # Create DataFrames for results and spot-check data\n","    consumption_based_ef = pd.DataFrame(consumption_rows)\n","    spot_check_df = pd.DataFrame(spot_check_data)\n","\n","    return consumption_based_ef, spot_check_df\n","\n"],"metadata":{"id":"x9rND4IsSJ8f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 4. Setup Data for a Specific Year\n","### 4.1 Example setup for a single year (2020)\n","def setup_year_data(year):\n","    if year < 2020 or year > 2024:\n","        raise ValueError(\"Valid years for generator data are 2020-2024.\")\n","\n","    # Aggregate generator data\n","    gen_output_df = aggregate_generator_data(year)\n","\n","    # Parse and clean demand data\n","    demand_url = f\"https://reports-public.ieso.ca/public/Demand/PUB_Demand_{year}.csv\"\n","    demand_path = f\"data/PUB_Demand_{year}.csv\"\n","    download_file(demand_url, demand_path)\n","    demand_df = parse_and_clean_demand(demand_path)\n","\n","    # Parse and clean trade flow data\n","    trade_flow_url = f\"https://reports-public.ieso.ca/public/IntertieScheduleFlowYear/PUB_IntertieScheduleFlowYear_{year}.csv\"\n","    trade_flow_path = f\"data/PUB_IntertieScheduleFlowYear_{year}.csv\"\n","    download_file(trade_flow_url, trade_flow_path)\n","    trade_flow_df = parse_and_clean_trade_flow(trade_flow_path)\n","\n","    return gen_output_df, demand_df, trade_flow_df\n"],"metadata":{"id":"U0LgBAcDSQg4","executionInfo":{"status":"ok","timestamp":1741719457485,"user_tz":240,"elapsed":45,"user":{"displayName":"Max St-Jacques","userId":"08144163697383063831"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["## 5. Main Execution\n","### 5.1 Main entry point\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","\n","### Notes: Downloaded generator data, demand data and flow data is all in MW\n","\n","def main():\n","    install_dependencies()\n","\n","    # Get emission rates\n","    emission_rates = get_emission_rates()\n","\n","    # Get emission factors for neighboring regions\n","    neighboring_emission_factors = get_neighboring_emission_factors()\n","\n","    #Download Data\n","    year = int(input(\"Enter the year for analysis (valid years are 2020-2024): \") or 2020)\n","    gen_output_df, demand_df, trade_flow_df = setup_year_data(year)\n","\n","\n","\n","    # Transform generator data to match new format\n","    transformed_gen_data = transform_generator_data(gen_output_df)\n","    # Ensure empty cells are filled with 0\n","    transformed_gen_data = transformed_gen_data.fillna(0)\n","\n","    # Transform the trade flow DataFrame\n","    transformed_trade_flow = transform_trade_flow(trade_flow_df)\n","\n","\n","    ## Output cleaned data for verification\n","    #print(\"\\nCleaned Generator Data Preview:\")\n","    #print(gen_output_df.head())\n","    #print(\"\\nTransformed Generator Data Preview:\")\n","    #print(transformed_gen_data.head())\n","    #print(\"\\nCleaned Demand Data Preview:\")\n","    #print(demand_df.head())\n","    #print(\"\\nCleaned Trade Flow Data Preview:\")\n","    #print(trade_flow_df.head())\n","\n","    ## Save the cleaned data to CSV files\n","    #output_dir = \"/content/drive/My Drive/cleaned_data\"\n","    #os.makedirs(output_dir, exist_ok=True)\n","\n","    #gen_output_df.to_csv(f\"{output_dir}/cleaned_generator_data_{year}.csv\", index=False)\n","    #print(f\"Cleaned generator data saved to {output_dir}/cleaned_generator_data_{year}.csv\")\n","\n","    #transformed_gen_data.to_csv(f\"{output_dir}/transformed_generator_data_{year}.csv\", index=False)\n","    #print(f\"Transformed generator data saved to {output_dir}/transformed_generator_data_{year}.csv\")\n","\n","    #demand_df.to_csv(f\"{output_dir}/cleaned_demand_data_{year}.csv\", index=False)\n","    #print(f\"Cleaned demand data saved to {output_dir}/cleaned_demand_data_{year}.csv\")\n","\n","    #trade_flow_df.to_csv(f\"{output_dir}/cleaned_trade_flow_data_{year}.csv\", index=False)\n","    #print(f\"Cleaned trade flow data saved to {output_dir}/cleaned_trade_flow_data_{year}.csv\")\n","\n","    #output_path = f\"{output_dir}/transformed_trade_flow_data_{year}.csv\"\n","    #transformed_trade_flow.to_csv(output_path, index=False)\n","    #print(f\"Transformed trade flow data saved to {output_path}\")\n","\n","\n","\n","    # Calculate supply-based EF and total output\n","    supplybased_ef, total_output_df = calculate_supply_based_ef(transformed_gen_data, emission_rates)\n","\n","    # Save the supply-based EF to CSV\n","    output_dir = \"/content/drive/My Drive/cleaned_data\"\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    supplybased_ef.to_csv(f\"{output_dir}/Supply-based_EF_{year}.csv\", index=False)\n","    print(f\"Supply-based EF data saved to: {output_dir}/Supply-based_EF_{year}.csv\")\n","\n","\n","    # Calculate consumption-based EF and retrieve spot-check data\n","    consumption_based_ef, spot_check_df = calculate_consumption_based_ef(\n","      supplybased_ef, demand_df, transformed_trade_flow, neighboring_emission_factors, total_output_df\n","      )\n","\n","    # Save the consumption-based EF to CSV\n","    consumption_based_ef.to_csv(f\"{output_dir}/Consumption-based_EF_{year}.csv\", index=False)\n","    print(f\"Consumption-based EF data saved to: {output_dir}/Consumption-based_EF_{year}.csv\")\n","\n","    # Save the spot-check data to CSV\n","    spot_check_df.to_csv(f\"{output_dir}/Spot_Check_Data_{year}.csv\", index=False)\n","    print(f\"Spot check data saved to: {output_dir}/Spot_Check_Data_{year}.csv\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":981},"id":"wjJyZhQYSixX","executionInfo":{"status":"error","timestamp":1741719408585,"user_tz":240,"elapsed":13315,"user":{"displayName":"Max St-Jacques","userId":"08144163697383063831"}},"outputId":"f19d3dba-7bef-427f-983b-94b5d392dd3f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","\n","Do you want to use custom emission rates for generator technologies? (y/n)\n","n\n","\n","Using default emission rates.\n","\n","Final Emission Rates (t CO2e/GWh):\n","             Emission Rate (t CO2e/GWh)\n","Biofuel                            6.15\n","Hydro                              0.00\n","Natural Gas                      525.00\n","Nuclear                            0.15\n","Solar                              6.15\n","Wind                               0.74\n","\n","Do you want to use custom emission factors for neighboring regions? (y/n)\n","n\n","\n","Using default emission factors.\n","\n","Final Emission Factors for Neighboring Regions (t CO2e/GWh):\n","           Emission Factor (t CO2e/GWh)\n","Manitoba                            2.2\n","Michigan                          502.0\n","Minnesota                         463.0\n","New York                          211.0\n","Quebec                              1.7\n","Enter the year for analysis (valid years are 2020-2024): 2025\n","Downloaded: data/PUB_GenOutputCapabilityMonth_202501.csv\n","Downloaded: data/PUB_GenOutputCapabilityMonth_202502.csv\n","Downloaded: data/PUB_GenOutputCapabilityMonth_202503.csv\n"]},{"output_type":"error","ename":"Exception","evalue":"Failed to download https://reports-public.ieso.ca/public/GenOutputCapabilityMonth/PUB_GenOutputCapabilityMonth_202504.csv (status code 404)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-126b58c7c75a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-126b58c7c75a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#Download Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the year for analysis (valid years are 2020-2024): \"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m2020\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mgen_output_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemand_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrade_flow_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_year_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-c673feffc2db>\u001b[0m in \u001b[0;36msetup_year_data\u001b[0;34m(year)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Aggregate generator data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgen_output_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_generator_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Parse and clean demand data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-3cc9fa5ac19b>\u001b[0m in \u001b[0;36maggregate_generator_data\u001b[0;34m(year)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Download the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Parse and clean the monthly data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-3cc9fa5ac19b>\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(url, save_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloaded: {save_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to download {url} (status code {response.status_code})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m### 3.2 Parse and Clean Generator Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: Failed to download https://reports-public.ieso.ca/public/GenOutputCapabilityMonth/PUB_GenOutputCapabilityMonth_202504.csv (status code 404)"]}]}]}